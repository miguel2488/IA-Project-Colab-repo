{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\viewer\\utils\\core.py:10: UserWarning: Recommended matplotlib backend is `Agg` for full skimage.viewer functionality.\n",
      "  warn(\"Recommended matplotlib backend is `Agg` for full \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libraries imported!!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function # Use a function definition from future version (say 3.x from 2.7 interpreter)\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cntk as C\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from cntk.io import UserMinibatchSource, StreamInformation, MinibatchData, Value\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "# Ensure we always get the same amount of randomness\n",
    "np.random.seed(0)\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.viewer import ImageViewer\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import misc\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "print('libraries imported!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bauer\\OneDrive para la Empresa\\Microsoft Capstone IA\n",
      "988\n",
      "988\n",
      "659\n",
      "659\n",
      "988\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "\n",
    "train_img_dir = os.getcwd() + '/Capstone data/train/'\n",
    "test_img_dir = os.getcwd() + '/Capstone data/test/'\n",
    "\n",
    "#spectrogram of current \n",
    "train_img_names_c = [x for x in os.listdir(train_img_dir) if x.endswith('_c.png')]\n",
    "\n",
    "#spectrogram of voltage\n",
    "train_img_names_v = [x for x in os.listdir(train_img_dir) if x.endswith('_v.png')]\n",
    "\n",
    "#spectrogram of current \n",
    "test_img_names_c = [x for x in os.listdir(test_img_dir) if x.endswith('_c.png')]\n",
    "\n",
    "#spectrogram of voltage\n",
    "test_img_names_v = [x for x in os.listdir(test_img_dir) if x.endswith('_v.png')]\n",
    "\n",
    "\n",
    "print(len(train_img_names_c))\n",
    "print(len(train_img_names_v))\n",
    "\n",
    "print(len(test_img_names_c))\n",
    "print(len(test_img_names_v))\n",
    "print(len(train_img_names_c))\n",
    "\n",
    "all_train_images = np.ones((len(train_img_names_c), 128, 118)) #if as_grey=True\n",
    "all_test_images = np.ones((len(test_img_names_c), 128, 118)) #if as_grey=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_train_images.shape (988, 128, 118)\n",
      "all_test_images.shape (659, 128, 118)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for im in train_img_names_c:\n",
    "\n",
    "    # Load an color image in grayscale\n",
    "    my_image = cv2.imread(train_img_dir + '/' + im,0)\n",
    "\n",
    "\n",
    "    all_train_images[i] = my_image\n",
    "    i = i + 1\n",
    "\n",
    "    \n",
    "i = 0\n",
    "for im in test_img_names_c:\n",
    "    #print(im)\n",
    "    my_image = cv2.imread(test_img_dir + '/' + im,0)\n",
    "\n",
    "\n",
    "    all_test_images[i] = my_image\n",
    "    i = i + 1    \n",
    "\n",
    "\n",
    "print(\"all_train_images.shape {0}\".format(all_train_images.shape))\n",
    "print(\"all_test_images.shape {0}\".format(all_test_images.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 30.  30.  30. ...  30.  30.  30.]\n",
      " [ 30.  30.  30. ...  30.  30.  30.]\n",
      " [ 30.  30.  30. ...  30.  30.  30.]\n",
      " ...\n",
      " [ 77.  73.  71. ... 194. 195. 200.]\n",
      " [ 78.  81.  82. ... 212. 212. 205.]\n",
      " [ 69.  63.  62. ... 179. 181. 185.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.5, 117.5, 127.5, -0.5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# look at the image\n",
    "#plt.imshow(my_image)\n",
    "\n",
    "\n",
    "\n",
    "sample_number = 12\n",
    "print(all_train_images[sample_number])\n",
    "plt.imshow(all_train_images[sample_number], cmap=\"gray_r\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************\n",
      "all_train_images.shape (988, 128, 118)\n",
      "data_train shape (988, 15104)\n",
      "[[ 38.  47.  51. ... 179. 184. 197.]\n",
      " [ 30.  30.  30. ... 177. 183. 196.]\n",
      " [ 62.  61.  64. ... 180. 187. 204.]\n",
      " ...\n",
      " [ 30.  30.  30. ... 180. 186. 200.]\n",
      " [ 67.  68.  66. ... 152. 159. 179.]\n",
      " [ 74.  61.  46. ... 153. 165. 159.]]\n",
      "**************************\n",
      "\n",
      "\n",
      "**************************\n",
      "all_test_images.shape (659, 128, 118)\n",
      "data_test shape (659, 15104)\n",
      "[[ 84.  81.  77. ... 179. 179. 172.]\n",
      " [ 30.  30.  30. ... 180. 181. 180.]\n",
      " [ 30.  30.  30. ... 152. 153. 148.]\n",
      " ...\n",
      " [ 56.  61.  62. ... 180. 180. 174.]\n",
      " [ 30.  30.  30. ... 179. 188. 205.]\n",
      " [ 70.  71.  69. ... 152. 154. 162.]]\n",
      "**************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "\n",
    "print(\"\\n**************************\")\n",
    "n_samples = len(all_train_images)\n",
    "\n",
    "print(\"all_train_images.shape {0}\".format(all_train_images.shape))\n",
    "data_train = all_train_images.reshape((n_samples, 15104)) #988, 15104, 4\n",
    "\n",
    "print(\"data_train shape {0}\".format(data_train.shape))\n",
    "print(data_train[:10])\n",
    "\n",
    "print(\"**************************\\n\")\n",
    "\n",
    "\n",
    "print(\"\\n**************************\")\n",
    "n_samples = len(all_test_images)\n",
    "\n",
    "print(\"all_test_images.shape {0}\".format(all_test_images.shape))\n",
    "data_test = all_test_images.reshape((n_samples, 15104)) #988, 15104, 4\n",
    "\n",
    "print(\"data_test shape {0}\".format(data_test.shape))\n",
    "print(data_test[:10])\n",
    "\n",
    "print(\"**************************\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "988\n",
      "(988, 2)\n"
     ]
    }
   ],
   "source": [
    "from numpy import genfromtxt\n",
    "\n",
    "\n",
    "train_labels_dir = os.getcwd() + '/'\n",
    "\n",
    "train_labels = genfromtxt(train_labels_dir + 'train_labels.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "print(len(train_labels))\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data and prepare the text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_labels shape is : (988, 2) \n",
      "\n",
      "x_train shape is:  (691, 15104) \n",
      " y_train shape is:  (691, 2) \n",
      "\n",
      "x_test shape is:  (297, 15104) \n",
      " y_test shape is:  (297, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(data_train, train_labels, test_size = 0.3, random_state = 54)\n",
    "\n",
    "print('train_labels shape is :', train_labels.shape, '\\n')\n",
    "print('x_train shape is: ', x_train.shape, '\\n',\n",
    "      'y_train shape is: ', y_train.shape, '\\n')\n",
    "\n",
    "print('x_test shape is: ', x_test.shape, '\\n', \n",
    "      'y_test shape is: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " def next_minibatch(self, num_samples, number_of_workers=1, worker_rank=0, device=None):\n",
    "        # Note that in this example we do not yet make use of number_of_workers or\n",
    "        # worker_rank, which will limit the minibatch source to single GPU / single node\n",
    "        # scenarios.\n",
    "\n",
    "        features = []\n",
    "        labels = []\n",
    "\n",
    "        sweep_end = False\n",
    "\n",
    "        sample_count = 0\n",
    "        \n",
    "        while (sample_count < num_samples):\n",
    "            if self.next_seq_idx == len(self.datafiles):\n",
    "                sweep_end = True\n",
    "                self.next_seq_idx = 0\n",
    "            \n",
    "            img = Image.open(self.datafiles[self.next_seq_idx][0])\n",
    "            \n",
    "            # Convert Image to numpy array. \n",
    "            f_data = np.array(img)\n",
    "          \n",
    "             \n",
    "            if (len(f_data.shape) == 2):\n",
    "                # Image has shape height x width. We need to transpose it to width x height\n",
    "                f_data = f_data.transpose(1, 0)    \n",
    "                \n",
    "                # This extra step is required to create data in the right shape that is acceptable during the training process.\n",
    "                # Ignoring this step will result in an error. Try commenting out the line below and observe the error.                \n",
    "                f_data = f_data[None, :]\n",
    "            elif (len(f_data.shape) == 3):\n",
    "                # Image has shape height x width x channel. We need to transpose it to channel x width x height            \n",
    "                f_data = f_data.transpose(2, 1, 0)\n",
    "            else:\n",
    "                print(\"Unexpected image type\")\n",
    "                return -1\n",
    "                        \n",
    "            #Assign the one-hot encoded label to l_data\n",
    "            l_data = self.label_onehot[self.datafiles[self.next_seq_idx][1]]\n",
    "            \n",
    "            features.append(f_data)\n",
    "            labels.append(l_data)\n",
    "                        \n",
    "            sample_count = sample_count + 1\n",
    "            self.next_seq_idx = self.next_seq_idx + 1\n",
    "            \n",
    "        num_seq = len(features)\n",
    "                               \n",
    "        f_data = Value(batch=np.asarray(features, dtype=np.float32))\n",
    "        l_data = Value(batch=np.asarray(labels, dtype=np.float32))    \n",
    "        \n",
    "        result = {            \n",
    "                cx: MinibatchData(f_data, num_seq, sample_count, sweep_end),\n",
    "                cy: MinibatchData(l_data, num_seq, sample_count, sweep_end)\n",
    "                }\n",
    "   \n",
    "\n",
    "        return result        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data files into a format compatible with CNTK text reader\n",
    "def savetxt(filename, data, hasLabels=True, labels=0):\n",
    "    dir = os.path.dirname(filename)\n",
    "\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    \n",
    "    print(\"Saving\", filename )\n",
    "    with open(filename, 'w') as f:\n",
    "        print(\"opened....\")\n",
    "        labels_ohe = list(map(' '.join, np.eye(11, dtype=np.uint).astype(str))) #for one hot encoding\n",
    "        index = 0\n",
    "        for row in data:            \n",
    "            row_str = row.astype(str)\n",
    "            if hasLabels:                               \n",
    "                label_str = labels_ohe[int(labels[index])]               \n",
    "            \n",
    "            feature_str = ' '.join(row_str)\n",
    "            \n",
    "            if hasLabels:\n",
    "                f.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "            else:\n",
    "                f.write('|features {}\\n'.format(feature_str))\n",
    "            \n",
    "            index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train text file...\n",
      "Saving C:\\Users\\bauer\\OneDrive para la Empresa\\Microsoft Capstone IA\\data/Out\\train.txt\n",
      "opened....\n",
      "Saving C:\\Users\\bauer\\OneDrive para la Empresa\\Microsoft Capstone IA\\data/Out\\test.txt\n",
      "opened....\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "train_labels_GT = y_train[:,1] #Get Ground truth\n",
    "test_labels_GT = y_test[:,1]\n",
    "\n",
    "print ('Writing train text file...')\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), \"data/Out\")\n",
    "\n",
    "\n",
    "savetxt(os.path.join(data_dir, \"train.txt\"), x_train, True, train_labels_GT)\n",
    "savetxt(os.path.join(data_dir, \"test.txt\"), x_test, True, test_labels_GT)\n",
    "\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Reader Deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a CTF formatted text (as mentioned above) using the CTF deserializer from a file\n",
    "def create_reader(path, is_training, input_dim = 128*118, num_label_classes = 11):\n",
    "    \n",
    "    labelStream = C.io.StreamDef(field='labels', shape=num_label_classes, is_sparse=False)\n",
    "    featureStream = C.io.StreamDef(field='features', shape=input_dim, is_sparse=False)\n",
    "    \n",
    "    deserailizer = C.io.CTFDeserializer(path, C.io.StreamDefs(labels = labelStream, features = featureStream))\n",
    "            \n",
    "    return C.io.MinibatchSource(deserailizer,\n",
    "       randomize = is_training, max_sweeps = C.io.INFINITELY_REPEAT if is_training else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function # Use a function definition from future version (say 3.x from 2.7 interpreter)\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cntk as C\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Ensure we always get the same amount of randomness\n",
    "np.random.seed(0)\n",
    "C.cntk_py.set_fixed_random_seed(1)\n",
    "C.cntk_py.force_deterministic_algorithms()\n",
    "\n",
    "# Define the data dimensions\n",
    "input_dim_model = (1, 128, 118)    # images are 28 x 28 with 1 channel of color (gray)\n",
    "input_dim = 128*118                # used by readers to treat input data as a vector\n",
    "num_output_classes = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = C.input_variable(input_dim_model)\n",
    "y = C.input_variable(num_output_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape of the first convolution layer: (8, 64, 59)\n",
      "Bias value of the last dense layer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# function to build model\n",
    "\n",
    "def create_model(features):\n",
    "    with C.layers.default_options(init=C.glorot_uniform(), activation=C.relu):\n",
    "            h = features\n",
    "            h = C.layers.Convolution2D(filter_shape=(5,5), \n",
    "                                       num_filters=8, \n",
    "                                       strides=(2,2), \n",
    "                                       pad=True, name='first_conv')(h)\n",
    "            h = C.layers.MaxPooling(filter_shape=(2,2), \n",
    "                                    strides=(2,2), name=\"first_max\")(h)            \n",
    "            h = C.layers.Convolution2D(filter_shape=(5,5), \n",
    "                                       num_filters=16, \n",
    "                                       strides=(2,2), \n",
    "                                       pad=True, name='second_conv')(h)\n",
    "            h = C.layers.MaxPooling(filter_shape=(3,3), \n",
    "                                    strides=(3,3), name=\"second_max\")(h)            \n",
    "            r = C.layers.Dense(num_output_classes, activation=None, name='classify')(h)\n",
    "            \n",
    "            return r\n",
    "        \n",
    "z = create_model(x)\n",
    "# Print the output shapes / parameters of different components\n",
    "print(\"Output Shape of the first convolution layer:\", z.first_conv.shape)\n",
    "print(\"Bias value of the last dense layer:\", z.classify.b.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 7835 parameters in 6 parameter tensors.\n"
     ]
    }
   ],
   "source": [
    "# Number of parameters in the network\n",
    "C.logging.log_number_of_parameters(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_criterion_function(model, labels):\n",
    "    loss = C.cross_entropy_with_softmax(model, labels)\n",
    "    errs = C.classification_error(model, labels)\n",
    "    return loss, errs # (model, labels) -> (loss, error metric)\n",
    "\n",
    "# Define a utility function to compute the moving average sum.\n",
    "# A more efficient implementation is possible with np.cumsum() function\n",
    "def moving_average(a, w=5):\n",
    "    if len(a) < w:\n",
    "        return a[:]    # Need to send a copy of the array\n",
    "    return [val if idx < w else sum(a[(idx-w):idx])/w for idx, val in enumerate(a)]\n",
    "\n",
    "\n",
    "# Defines a utility that prints the training progress\n",
    "def print_training_progress(trainer, mb, frequency, verbose=1):\n",
    "    training_loss = \"NA\"\n",
    "    eval_error = \"NA\"\n",
    "\n",
    "    if mb%frequency == 0:\n",
    "        training_loss = trainer.previous_minibatch_loss_average\n",
    "        eval_error = trainer.previous_minibatch_evaluation_average\n",
    "        if verbose: \n",
    "            print (\"Minibatch: {0}, Loss: {1:.4f}, Error: {2:.2f}%\".format(mb, training_loss, eval_error*100))\n",
    "        \n",
    "    return mb, training_loss, eval_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_train(train_reader, model_func, train_minibatch_size = 35, num_samples_per_sweep = 15000, \n",
    "              num_sweeps_to_train_with = 10, learning_rate = 0.1, training_progress_output_freq = 500):\n",
    "    \n",
    "    global plotdata\n",
    "    \n",
    "    print(\"Training minibatch size = \" + str(train_minibatch_size))\n",
    "    print(\"Number of samples per sweep = \" + str(num_samples_per_sweep))\n",
    "    print(\"Number of sweeps to train with = \" + str(num_sweeps_to_train_with))\n",
    "    print(\"Learning rate = \" + str(learning_rate))\n",
    "    \n",
    "    \n",
    "    # Instantiate the model function; x is the input (feature) variable \n",
    "    # We will scale the input image pixels within 0-1 range by dividing all input value by 255.\n",
    "    model = model_func(cx/255)\n",
    "    \n",
    "    # Instantiate the loss and error function\n",
    "    loss, label_error = create_criterion_function(model, cy)\n",
    "    \n",
    "    # Instantiate the trainer object to drive the model training\n",
    "    lr_schedule = C.learning_rate_schedule(learning_rate, C.UnitType.minibatch)\n",
    "    learner = C.sgd(cz.parameters, lr_schedule)\n",
    "    trainer = C.Trainer(cz, (loss, label_error), [learner])\n",
    "    \n",
    "    # Initialize the parameters for the trainer\n",
    "    num_minibatches_to_train = (num_samples_per_sweep * num_sweeps_to_train_with) / train_minibatch_size\n",
    "    \n",
    "    import time\n",
    "    # Start a timer\n",
    "    start = time.time()\n",
    "    \n",
    "    print(\"Number of mini batches to train = \" + str(num_minibatches_to_train))\n",
    "    \n",
    "    for i in range(0, int(num_minibatches_to_train)):\n",
    "        # Read a mini batch from the training dataset\n",
    "        data=train_reader.next_minibatch(train_minibatch_size)\n",
    "        \n",
    "        trainer.train_minibatch(data)\n",
    "        mb, training_loss, eval_error, time_since_start = print_training_progress(trainer, i, \n",
    "                                                                                  training_progress_output_freq, start, \n",
    "                                                                                  verbose=1)\n",
    "        \n",
    "        if ((i % training_progress_output_freq) == 0):\n",
    "            plotdata[\"minibatch_num\"].append(mb)\n",
    "            plotdata[\"loss\"].append(training_loss)\n",
    "            plotdata[\"error\"].append(eval_error)\n",
    "            plotdata[\"time\"].append(time_since_start)\n",
    "     \n",
    "    # Print training time\n",
    "    print(\"Training took {:.1f} sec\".format(time.time() - start))\n",
    "    \n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_test(trainer, test_reader, num_test_samples = 3000, test_minibatch_size = 50, print_frequency = 500):\n",
    "    \n",
    "    # Test data for trained model       \n",
    "    num_minibatches_to_test = num_test_samples // test_minibatch_size\n",
    "\n",
    "    print(\"Number of minibatches to test = \" + str(num_minibatches_to_test))\n",
    "    test_result = 0.0   \n",
    "\n",
    "    for i in range(0, num_minibatches_to_test):               \n",
    "        # We are loading test data in batches specified by test_minibatch_size\n",
    "        data = test_reader.next_minibatch(test_minibatch_size)\n",
    "            \n",
    "        eval_error = trainer.test_minibatch(data)\n",
    "        test_result = test_result + eval_error\n",
    "        \n",
    "        if ((i % print_frequency) == 0):\n",
    "            print(\"Testing minibatch \" + str(i) + \" Eval error = \" + str(eval_error))\n",
    "\n",
    "    # Average of evaluation errors of all test minibatches\n",
    "    print(\"Average test error: {0:.2f}%\".format(test_result * 100 / num_minibatches_to_test))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_test(train_reader, test_reader, model_func, num_sweeps_to_train_with=10):\n",
    "    \n",
    "    # Instantiate the model function; x is the input (feature) variable \n",
    "    # We will scale the input image pixels within 0-1 range by dividing all input value by 255.\n",
    "    model = model_func(x/255)\n",
    "    \n",
    "    # Instantiate the loss and error function\n",
    "    loss, label_error = create_criterion_function(model, y)\n",
    "    \n",
    "    # Instantiate the trainer object to drive the model training\n",
    "    learning_rate = 0.2\n",
    "    lr_schedule = C.learning_rate_schedule(learning_rate, C.UnitType.minibatch)\n",
    "    learner = C.sgd(z.parameters, lr_schedule)\n",
    "    trainer = C.Trainer(z, (loss, label_error), [learner])\n",
    "    \n",
    "    # Initialize the parameters for the trainer\n",
    "    minibatch_size = 1\n",
    "    num_samples_per_sweep = 691\n",
    "    num_minibatches_to_train = (num_samples_per_sweep * num_sweeps_to_train_with) / minibatch_size\n",
    "    \n",
    "    # Map the data streams to the input and labels.\n",
    "    input_map={\n",
    "        y  : train_reader.streams.labels,\n",
    "        x  : train_reader.streams.features\n",
    "    } \n",
    "    \n",
    "    # Uncomment below for more detailed logging\n",
    "    training_progress_output_freq = 10\n",
    "     \n",
    "    # Start a timer\n",
    "    start = time.time()\n",
    "\n",
    "    for i in range(0, int(num_minibatches_to_train)):\n",
    "        # Read a mini batch from the training data file\n",
    "        data=train_reader.next_minibatch(minibatch_size, input_map=input_map) \n",
    "        trainer.train_minibatch(data)\n",
    "        print_training_progress(trainer, i, training_progress_output_freq, verbose=1)\n",
    "     \n",
    "    # Print training time\n",
    "    print(\"Training took {:.1f} sec\".format(time.time() - start))\n",
    "    \n",
    "    # Test the model\n",
    "    test_input_map = {\n",
    "        y  : test_reader.streams.labels,\n",
    "        x  : test_reader.streams.features\n",
    "    }\n",
    "\n",
    "    # Test data for trained model\n",
    "    test_minibatch_size = 1\n",
    "    num_samples = 297\n",
    "    num_minibatches_to_test = num_samples // test_minibatch_size\n",
    "\n",
    "    test_result = 0.0   \n",
    "\n",
    "    for i in range(num_minibatches_to_test):\n",
    "    \n",
    "        # We are loading test data in batches specified by test_minibatch_size\n",
    "        # Each data point in the minibatch is a MNIST digit image of 784 dimensions \n",
    "        # with one pixel per dimension that we will encode / decode with the \n",
    "        # trained model.\n",
    "        data = test_reader.next_minibatch(test_minibatch_size, input_map=test_input_map)\n",
    "        eval_error = trainer.test_minibatch(data)\n",
    "        test_result = test_result + eval_error\n",
    "\n",
    "    # Average of evaluation errors of all test minibatches\n",
    "    print(\"Average test error: {0:.2f}%\".format(test_result*100 / num_minibatches_to_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'data/out/train.txt'\n",
    "test_file = 'data/out/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(train_file, test_file, train_minibatch_size = 35, num_samples_per_sweep = 988, \n",
    "                   num_sweeps_to_train_with = 10, learning_rate = 0.1,):\n",
    "    global z\n",
    "    \n",
    "    z = create_model(x)\n",
    "    reader_train = create_reader(train_file, input_dim)\n",
    "    reader_test = create_reader(test_file, input_dim)\n",
    "    train_test(reader_train, reader_test, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCharts():\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.subplot(211)\n",
    "    plt.plot(plotdata[\"minibatch_num\"], plotdata[\"loss\"], 'b--')\n",
    "    plt.xlabel('Minibatch number')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Minibatch run vs. Training loss')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.plot(plotdata[\"minibatch_num\"], plotdata[\"error\"], 'r--')\n",
    "    plt.xlabel('Minibatch number')\n",
    "    plt.ylabel('Label Prediction Error')\n",
    "    plt.title('Minibatch run vs. Label Prediction Error')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cntk.ops.functions import load_model\n",
    "\n",
    "def loadAndEvalModel(modelFileName, eval_file, eval_minibatch_size = 25):\n",
    "    global z\n",
    "    z = load_model(modelFileName)\n",
    "    \n",
    "    out = C.softmax(cz)\n",
    "    \n",
    "    # Read the data for evaluation    \n",
    "    reader_eval = create_reader(eval_file, input_dim, num_output_classes)\n",
    "\n",
    "    data = reader_eval.next_minibatch(eval_minibatch_size)\n",
    "    predicted_label_prob = []\n",
    "    \n",
    "    img_label = 1\n",
    "    img_data = 1\n",
    "    \n",
    "\n",
    "    for d in data:\n",
    "        if (len(data[d].shape) == 2):\n",
    "            img_label = data[d].as_sequences()\n",
    "        else:\n",
    "            img_data = data[d].as_sequences()\n",
    "            \n",
    "    # Note the division by 255. This is to match how the data was prepared during training.\n",
    "    # Skipping the division will give incorrect results  \n",
    "    predicted_label_prob = [out.eval(img_data[i] / 255) for i in range(0, len(img_data))]\n",
    "       \n",
    "    # Find the index with the maximum value for both predicted as well as the ground truth\n",
    "    pred = [np.argmax(predicted_label_prob[i]) for i in range(len(predicted_label_prob))]\n",
    "    gtlabel = [np.argmax(img_label[i]) for i in range(len(img_label))]\n",
    "    \n",
    "    num_errors = 0\n",
    "    for i in range(0, eval_minibatch_size):\n",
    "        if (pred[i] != gtlabel[i]):\n",
    "            num_errors = num_errors + 1\n",
    "    \n",
    "    #print(\"Label    :\", gtlabel)\n",
    "    #print(\"Predicted:\", pred)\n",
    "    print(\"Number of errors: \" + str(num_errors))\n",
    "    print(\"Error % = \" + str(100 * num_errors / eval_minibatch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 7835 parameters in 6 parameter tensors.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in method 'ctf_deserializer', argument 1 of type 'std::wstring const &'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-242911ff9630>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_number_of_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtrain_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Save the model to a file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-d98e5c0a876f>\u001b[0m in \u001b[0;36mtrain_test\u001b[1;34m(train_file, test_file, train_minibatch_size, num_samples_per_sweep, num_sweeps_to_train_with, learning_rate)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mreader_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mreader_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtrain_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreader_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-d98e5c0a876f>\u001b[0m in \u001b[0;36mtrain_test\u001b[1;34m(train_file, test_file, train_minibatch_size, num_samples_per_sweep, num_sweeps_to_train_with, learning_rate)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mreader_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mreader_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtrain_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreader_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-334a97047763>\u001b[0m in \u001b[0;36mcreate_reader\u001b[1;34m(path, is_training, input_dim, num_label_classes)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mfeatureStream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamDef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mdeserailizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCTFDeserializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamDefs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabelStream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatureStream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     return C.io.MinibatchSource(deserailizer,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\cntk\\io\\__init__.py\u001b[0m in \u001b[0;36mCTFDeserializer\u001b[1;34m(filename, streams)\u001b[0m\n\u001b[0;32m    935\u001b[0m     sc = [cntk_py.StreamConfiguration(\n\u001b[0;32m    936\u001b[0m         k, s.dim, s.is_sparse, s.stream_alias, s['defines_mb_size']) for k, s in streams.items()]\n\u001b[1;32m--> 937\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcntk_py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctf_deserializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    938\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mCBFDeserializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstreams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in method 'ctf_deserializer', argument 1 of type 'std::wstring const &'"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "z = create_model(x)\n",
    "\n",
    "# Number of parameters in the network\n",
    "C.logging.log_number_of_parameters(z)\n",
    "\n",
    "train_test(train_file, test_file)\n",
    "\n",
    "# Save the model to a file\n",
    "z.save(\"./CNN-capstone-img.dnn\")\n",
    "\n",
    "plotCharts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the save_text function to avoid malformed input file error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data files into a format compatible with CNTK text reader\n",
    "def savetxt(filename, data, hasLabels=True, labels=0):\n",
    "    dir = os.path.dirname(filename)\n",
    "\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    \n",
    "    print(\"Saving\", filename )\n",
    "    with open(filename, 'w') as f:\n",
    "        print(\"opened....\")\n",
    "        labels_ohe = list(map(' '.join, np.eye(11, dtype=np.uint).astype(str))) #for one hot encoding\n",
    "        index = 0\n",
    "        for row in data:            \n",
    "            row_str = row.astype(str)\n",
    "            if hasLabels:                               \n",
    "                label_str = labels_ohe[int(labels[index])]               \n",
    "            \n",
    "            feature_str = ' '.join(row_str)\n",
    "            \n",
    "            if hasLabels:\n",
    "                f.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "            else:\n",
    "                f.write('|labels {} |features {}\\n'.format(labels_ohe[1], feature_str))\n",
    "\n",
    "            \n",
    "            index = index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model evaluation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train text file...\n",
      "Saving C:\\Users\\bauer\\OneDrive para la Empresa\\Microsoft Capstone IA\\data/Out\\test_eval.txt\n",
      "opened....\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print ('Writing train text file...')\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), \"data/Out\")\n",
    "\n",
    "\n",
    "savetxt(os.path.join(data_dir, \"test_eval.txt\"), data_test, False)\n",
    "\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data for evaluation\n",
    "eval_file = 'C:/Users/bauer/OneDrive para la Empresa/Microsoft Capstone IA/data/Out/test_eval.txt'\n",
    "reader_eval=create_reader(eval_file, False, input_dim, num_output_classes)\n",
    "\n",
    "eval_minibatch_size = 25\n",
    "eval_input_map = {x: reader_eval.streams.features, y:reader_eval.streams.labels} \n",
    "\n",
    "data = reader_eval.next_minibatch(eval_minibatch_size, input_map=eval_input_map)\n",
    "\n",
    "img_label = data[y].asarray()\n",
    "img_data = data[x].asarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label    : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Predicted: [2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "# reshape img_data to: M x 1 x 128 x 118 to be compatible with model\n",
    "img_data = np.reshape(img_data, (eval_minibatch_size, 1, 128, 118))\n",
    "\n",
    "predicted_label_prob = [out.eval(img_data[i]) for i in range(len(img_data))]\n",
    "\n",
    "\n",
    "# Find the index with the maximum value for both predicted as well as the ground truth\n",
    "pred = [np.argmax(predicted_label_prob[i]) for i in range(len(predicted_label_prob))]\n",
    "gtlabel = [np.argmax(img_label[i]) for i in range(len(img_label))]\n",
    "\n",
    "\n",
    "print(\"Label    :\", gtlabel[:25])\n",
    "print(\"Predicted:\", pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optionally modify model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from cntk.layers.layers import AveragePooling\n",
    "\n",
    "def create_model(features):\n",
    "    with C.layers.default_options(init = C.glorot_uniform(), activation = C.relu):\n",
    "            h = features\n",
    "            \n",
    "            h = C.layers.Convolution2D(filter_shape=(5,5), \n",
    "                                       num_filters=8, \n",
    "                                       strides=(1,1), \n",
    "                                       pad=True, name='first_conv')(h)\n",
    "            \n",
    "            p =  AveragePooling((3,3), strides=1)\n",
    "            \n",
    "            ph = p(h)\n",
    "            \n",
    "            h = C.layers.Convolution2D(filter_shape=(5,5), \n",
    "                                       num_filters=16, \n",
    "                                       strides=(1,1), \n",
    "                                       pad=True, name='second_conv')(h)\n",
    "            \n",
    "            p =  AveragePooling((3,3), strides=1)\n",
    "            \n",
    "            ph = p(h)\n",
    "            \n",
    "            r = C.layers.Dense(num_output_classes, activation = None, name='classify')(h)\n",
    "            return r'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optionally train the model on the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Save the data files into a format compatible with CNTK text reader\n",
    "def savetxt(filename, data, hasLabels=True, labels=0):\n",
    "    dir = os.path.dirname(filename)\n",
    "\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    \n",
    "    print(\"Saving\", filename )\n",
    "    with open(filename, 'w') as f:\n",
    "        print(\"opened....\")\n",
    "        labels_ohe = list(map(' '.join, np.eye(11, dtype=np.uint).astype(str))) #for one hot encoding\n",
    "        index = 0\n",
    "        for row in data:            \n",
    "            row_str = row.astype(str)\n",
    "            if hasLabels:                               \n",
    "                label_str = labels_ohe[int(labels[index])]               \n",
    "            \n",
    "            feature_str = ' '.join(row_str)\n",
    "            \n",
    "            if hasLabels:\n",
    "                f.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "            else:\n",
    "                f.write('|labels {} |features {}\\n'.format(labels_ohe[1], feature_str))\n",
    "\n",
    "            \n",
    "            index = index + 1\n",
    "\n",
    "\n",
    "\n",
    "train_labels_GT = train_labels[:,1] #Get Ground truth\n",
    "\n",
    "\n",
    "print ('Writing train text file...')\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), \"data/Out\")\n",
    "\n",
    "\n",
    "savetxt(os.path.join(data_dir, \"train.txt\"), data_train, True, train_labels_GT)\n",
    "savetxt(os.path.join(data_dir, \"test.txt\"), data_test, False)\n",
    "\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "do_train_test()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optionally make predictions again from the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# reshape img_data to: M x 1 x 128 x 118 to be compatible with model\n",
    "img_data = np.reshape(img_data, (eval_minibatch_size, 1, 128, 118))\n",
    "\n",
    "predicted_label_prob = [out.eval(img_data[i]) for i in range(len(img_data))]\n",
    "\n",
    "\n",
    "# Find the index with the maximum value for both predicted as well as the ground truth\n",
    "pred = [np.argmax(predicted_label_prob[i]) for i in range(len(predicted_label_prob))]\n",
    "gtlabel = [np.argmax(img_label[i]) for i in range(len(img_label))]\n",
    "\n",
    "\n",
    "print(\"Label    :\", gtlabel[:25])\n",
    "print(\"Predicted:\", pred)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "id_labels = pd.read_csv('test_labels.csv')\n",
    "predictions = pd.DataFrame(data = pred, columns = ['appliance'])\n",
    "predictions['id'] = id_labels['names']\n",
    "predictions = predictions[['id', 'appliance']]\n",
    "\n",
    "\n",
    "#SAVE CSV\n",
    "predictions.to_csv('Caps_Preds.csv', index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
